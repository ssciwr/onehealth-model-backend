{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import geopandas as gpd\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from typing import Callable, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Analysis NUTS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepaths\n",
    "nuts_filepath = \"../../data/in/NUTS_RG_10M_2024_4326.shp/NUTS_RG_10M_2024_4326.shp\"\n",
    "era5_filepath = \"../../data/in/ERA5land_global_t2m_dailyStats_mean_01Deg_2024_08_data.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load NetCDF temperature data ---\n",
    "era5_ds = xr.open_dataset(era5_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m = era5_ds[\"t2m\"].isel(valid_time=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "t2m.plot(ax=ax, transform=ccrs.PlateCarree(), cmap=\"coolwarm\")\n",
    "ax.coastlines()\n",
    "ax.set_title(\"T2M - Global\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load NUTS shapefile ---\n",
    "nuts_gdf = gpd.read_file(nuts_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty figure and add an axis\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# plot a basic map of the world\n",
    "nuts_gdf.plot(ax=ax, color=\"lightgray\", edgecolor=\"black\", alpha=0.5)\n",
    "\n",
    "# turn off axis ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# set the plot title\n",
    "plt.title(\"Basic Map of World with GeoPandas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding Box defining EUROPA\n",
    "europe_bounds_manual = {\n",
    "    \"min_longitude\": -10,\n",
    "    \"min_latitude\": 35,\n",
    "    \"max_longitude\": 40,\n",
    "    \"max_latitude\": 72,\n",
    "}\n",
    "\n",
    "# Bounding Box defining EUROPA\n",
    "minx, miny, maxx, maxy = nuts_gdf.total_bounds\n",
    "europe_bounds_nuts = {\n",
    "    \"min_longitude\": minx,\n",
    "    \"min_latitude\": miny,\n",
    "    \"max_longitude\": maxx,\n",
    "    \"max_latitude\": maxy,\n",
    "}\n",
    "\n",
    "# bounding_box = europe_bounds_manual\n",
    "bounding_box = europe_bounds_nuts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Cropping NETCDF4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = era5_ds.latitude.values\n",
    "is_lat_descending = lat[0] > lat[-1]\n",
    "print(f\"Descending latitude: {is_lat_descending}\")\n",
    "\n",
    "lat_slice = (\n",
    "    slice(bounding_box[\"max_latitude\"], bounding_box[\"min_latitude\"])\n",
    "    if is_lat_descending\n",
    "    else slice(bounding_box[\"min_latitude\"], bounding_box[\"max_latitude\"])\n",
    ")\n",
    "\n",
    "lon_slice = slice(bounding_box[\"min_longitude\"], bounding_box[\"max_longitude\"])\n",
    "\n",
    "cropped_ds = era5_ds.sel(latitude=lat_slice, longitude=lon_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Cropping NUTS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_gdf = nuts_gdf[\n",
    "    (nuts_gdf.geometry.bounds[\"minx\"] >= bounding_box[\"min_longitude\"])\n",
    "    & (nuts_gdf.geometry.bounds[\"miny\"] >= bounding_box[\"min_latitude\"])\n",
    "    & (nuts_gdf.geometry.bounds[\"maxx\"] <= bounding_box[\"max_longitude\"])\n",
    "    & (nuts_gdf.geometry.bounds[\"maxy\"] <= bounding_box[\"max_latitude\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Plot data in the same map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m = cropped_ds[\"t2m\"].isel(valid_time=0)\n",
    "\n",
    "# Ensure the same CRS\n",
    "nuts_gdf = nuts_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# --- 3. Plot both together ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Plot temperature raster (use .plot() directly from xarray)\n",
    "t2m.plot(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=\"coolwarm\",\n",
    "    cbar_kwargs={\"label\": \"Temperature (Celsius)\"},\n",
    ")\n",
    "\n",
    "# Plot NUTS regions\n",
    "nuts_gdf.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=0.5)\n",
    "\n",
    "# Add base map decorations\n",
    "ax.set_title(\"ERA5 T2M and NUTS3 Regions - August 2024\", fontsize=14)\n",
    "ax.coastlines()\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Experiments Interpolation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolator(x_data, y_data, x_new):\n",
    "    \"\"\"Wrap a linear interpolation function.\"\"\"\n",
    "    try:\n",
    "        result = np.interp(x_new, x_data, y_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Caught exception: {type(e).__name__} - {e}\")\n",
    "        raise  # re-raise the exception if you want it propagated\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bspline_interpolator(x_data, y_data, x_new, degree=1):\n",
    "    \"\"\"Wrap a B-spline interpolation function.\"\"\"\n",
    "    try:\n",
    "        bspl = make_interp_spline(x_data, y_data, k=degree)\n",
    "        result = bspl(x_new)\n",
    "    except Exception as e:\n",
    "        print(f\"Caught exception: {type(e).__name__} - {e}\")\n",
    "        raise  # re-raise the exception if you want it propagated\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolator_function(\n",
    "    x_data: np.ndarray,\n",
    "    y_data: np.ndarray,\n",
    "    method: str = \"linear\",\n",
    "    b_spline_degree: int = 3,\n",
    ") -> Callable[[Union[float, np.ndarray]], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create an interpolation function using specified method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_data : array-like, shape (n,)\n",
    "        Independent variable data points (must be sorted ascending).\n",
    "    y_data : array-like, shape (n,)\n",
    "        Dependent variable data points.\n",
    "    method : str, optional\n",
    "        Interpolation method: \"linear\" or \"bspline\" (default \"linear\").\n",
    "    b_spline_degree : int, optional\n",
    "        Degree of B-spline (default 3). Used only if method=\"bspline\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    interpolator : function\n",
    "        Function accepting scalar or array x_new and returning interpolated y values.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If inputs are invalid or unsupported method is specified.\n",
    "    \"\"\"\n",
    "\n",
    "    x_data = np.asarray(x_data)\n",
    "    y_data = np.asarray(y_data)\n",
    "\n",
    "    if x_data.ndim != 1 or y_data.ndim != 1:\n",
    "        raise ValueError(\"x_data and y_data must be one-dimensional arrays.\")\n",
    "    if len(x_data) != len(y_data):\n",
    "        raise ValueError(\"x_data and y_data must have the same length.\")\n",
    "    if len(x_data) < 2:\n",
    "        raise ValueError(\"At least two data points are required for interpolation.\")\n",
    "\n",
    "    # Check sortedness\n",
    "    if not np.all(np.diff(x_data) >= 0):\n",
    "        raise ValueError(\"x_data must be sorted in ascending order.\")\n",
    "\n",
    "    if method not in {\"linear\", \"bspline\"}:\n",
    "        raise ValueError(\n",
    "            f\"Unsupported interpolation method '{method}'. Choose 'linear' or 'bspline'.\"\n",
    "        )\n",
    "\n",
    "    if method == \"bspline\":\n",
    "        if not isinstance(b_spline_degree, int) or not (1 <= b_spline_degree <= 5):\n",
    "            raise ValueError(\"b_spline_degree must be an integer between 1 and 5.\")\n",
    "        try:\n",
    "            spline_obj = make_interp_spline(x_data, y_data, k=b_spline_degree)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to create spline: {e}\") from e\n",
    "\n",
    "        def bspline_interpolator(x_new):\n",
    "            return spline_obj(x_new)\n",
    "\n",
    "    def linear_interpolator(x_new):\n",
    "        return np.interp(x_new, x_data, y_data)\n",
    "\n",
    "    return bspline_interpolator if method == \"bspline\" else linear_interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth curve\n",
    "x_ground_truth = np.linspace(-6, 6, 50)\n",
    "y_ground_truth = np.power(x_ground_truth, 3)\n",
    "\n",
    "# Data points\n",
    "x_data = np.arange(-4, 5, 2)\n",
    "y_data = np.power(x_data, 3)\n",
    "\n",
    "# Data for evaluation\n",
    "x_test = np.linspace(-6, 6, 20)\n",
    "y_test = linear_interpolator(x_data, y_data, x_new=x_test)\n",
    "\n",
    "plt.plot(x_ground_truth, y_ground_truth, \"--\", label=\"Ground Truth\", color=\"blue\")\n",
    "plt.plot(x_data, y_data, \"D\", label=\"Data\", color=\"orange\")\n",
    "plt.plot(x_test, y_test, \"-*\", label=\"Linear Interpolation\", color=\"green\")\n",
    "\n",
    "# Shade regions where data is missing (e.g., x < 4 and x > 4)\n",
    "plt.axvspan(min(x_data), -7, color=\"gray\", alpha=0.3)\n",
    "plt.axvspan(7, max(x_data), color=\"gray\", alpha=0.3, label=\"No Data\")\n",
    "\n",
    "plt.xlim(-7, 7)  # Set x-axis limits from 0 to 4\n",
    "plt.ylim(-100, 100)  # Set y-axis limits from 3 to 7\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth curve\n",
    "x_ground_truth = np.linspace(-6, 6, 50)\n",
    "y_ground_truth = np.power(x_ground_truth, 3)\n",
    "\n",
    "# Data points\n",
    "x_data = np.arange(-4, 5, 2)\n",
    "y_data = np.power(x_data, 3)\n",
    "\n",
    "# Data for evaluation\n",
    "x_test = np.linspace(-6, 6, 20)\n",
    "y_test = bspline_interpolator(x_data, y_data, x_new=x_test, degree=3)\n",
    "\n",
    "plt.plot(x_ground_truth, y_ground_truth, \"--\", label=\"Ground Truth\", color=\"blue\")\n",
    "plt.plot(x_data, y_data, \"D\", label=\"Data\", color=\"orange\")\n",
    "plt.plot(x_test, y_test, \"-*\", label=\"Linear Interpolation\", color=\"green\")\n",
    "\n",
    "# Shade regions where data is missing (e.g., x < 4 and x > 4)\n",
    "plt.axvspan(min(x_data), -7, color=\"gray\", alpha=0.3)\n",
    "plt.axvspan(7, max(x_data), color=\"gray\", alpha=0.3, label=\"No Data\")\n",
    "\n",
    "plt.xlim(-7, 7)  # Set x-axis limits from 0 to 4\n",
    "plt.ylim(-100, 100)  # Set y-axis limits from 3 to 7\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = interpolator_function(x_data, y_data, method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# Ground Truth curve\n",
    "x_ground_truth = np.linspace(-6, 6, 50)\n",
    "y_ground_truth = np.power(x_ground_truth, 3)\n",
    "\n",
    "# Data points\n",
    "x_data = np.arange(-4, 5, 2)\n",
    "y_data = np.power(x_data, 3)\n",
    "\n",
    "# Data for evaluation\n",
    "x_test = np.linspace(-6, 6, 20)\n",
    "interp_fun = interpolator_function(x_data, y_data, method=\"bspline\", b_spline_degree=1)\n",
    "y_test = interp_fun(x_test)\n",
    "\n",
    "plt.plot(x_ground_truth, y_ground_truth, \"--\", label=\"Ground Truth\", color=\"blue\")\n",
    "plt.plot(x_data, y_data, \"D\", label=\"Data\", color=\"orange\")\n",
    "plt.plot(x_test, y_test, \"-*\", label=\"Linear Interpolation\", color=\"green\")\n",
    "\n",
    "# Shade regions where data is missing (e.g., x < 4 and x > 4)\n",
    "plt.axvspan(min(x_data), -7, color=\"gray\", alpha=0.3)\n",
    "plt.axvspan(7, max(x_data), color=\"gray\", alpha=0.3, label=\"No Data\")\n",
    "\n",
    "plt.xlim(-7, 7)  # Set x-axis limits from 0 to 4\n",
    "plt.ylim(-100, 100)  # Set y-axis limits from 3 to 7\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_ds[\"valid_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature_at_point = era5_ds.t2m.sel(\n",
    "#    latitude=-10,\n",
    "#    longitude=35,\n",
    "#    valid_time=\"2024-08-01\",\n",
    "#    method=\"nearest\",  # Finds the closest grid point\n",
    "# ).item()  # .item()\n",
    "\n",
    "# temperature_at_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# era5_ds[\"t2m\"] = era5_ds[\"t2m\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature_at_point1 = era5_ds.t2m.sel(\n",
    "#    latitude=-10,\n",
    "#    longitude=35,\n",
    "#    valid_time=\"2024-08-01\",\n",
    "#    method=\"nearest\",  # Finds the closest grid point\n",
    "# ).item()  # .item()\n",
    "\n",
    "# temperature_at_point1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# era5_ds[\"t2m\"][0, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from R0_pip_fun import R0_pip_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_ds[\"t2m\"] = xr.DataArray(\n",
    "    R0_pip_fun(era5_ds[\"t2m\"].values),\n",
    "    dims=era5_ds[\"t2m\"].dims,\n",
    "    coords=era5_ds[\"t2m\"].coords,\n",
    "    attrs=era5_ds[\"t2m\"].attrs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_ds[\"t2m\"].dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_ds[\"t2m\"].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = era5_ds[\"t2m\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_values = numpy_array[~np.isnan(numpy_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiny_netcdf(filename=\"tiny_temp_data.nc\"):\n",
    "    \"\"\"\n",
    "    Creates a tiny NetCDF file with 'temperature', 'latitude', 'longitude',\n",
    "    and 'valid_time' variables, including some NaN values for interpolation testing.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the NetCDF file to create.\n",
    "    \"\"\"\n",
    "    # 1. Define simple coordinates\n",
    "    times = pd.date_range(\"2024-01-01\", periods=3, freq=\"12H\")  # 3 time points\n",
    "    latitudes = np.array([40.0, 40.5, 41.0])  # 3 latitude points\n",
    "    longitudes = np.array([10.0, 10.5, 11.0])  # 3 longitude points\n",
    "\n",
    "    # 2. Create a small NumPy array for temperature data\n",
    "    #    Shape: (time, lat, lon) = (3, 3, 3)\n",
    "    #    Introduce some NaNs intentionally for testing interpolation of missing values\n",
    "    temp_data = np.array(\n",
    "        [\n",
    "            [\n",
    "                [0, 0.85, 2.35],\n",
    "                [1.35, np.nan, 2.85],\n",
    "                [1.85, 3.35, 3.85],\n",
    "            ],\n",
    "            [\n",
    "                [2.85, np.nan, 4.85],\n",
    "                [4.35, 4.85, 5.85],\n",
    "                [5.35, 6.35, np.nan],\n",
    "            ],  # NaN at this point\n",
    "            [\n",
    "                [6.85, 7.85, 8.85],\n",
    "                [7.35, 8.35, 9.35],\n",
    "                [7.85, 8.85, 9.85],\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 3. Create an xarray DataArray for temperature\n",
    "    temperature_da = xr.DataArray(\n",
    "        temp_data,\n",
    "        coords={\"valid_time\": times, \"latitude\": latitudes, \"longitude\": longitudes},\n",
    "        dims=[\"valid_time\", \"latitude\", \"longitude\"],\n",
    "        name=\"t2m\",\n",
    "        attrs={\"units\": \"Celsius\", \"long_name\": \"Air Temperature at Surface\"},\n",
    "    )\n",
    "\n",
    "    # 4. Create an xarray Dataset from the DataArray\n",
    "    ds = xr.Dataset({\"temperature\": temperature_da})\n",
    "\n",
    "    # Add some global attributes (optional)\n",
    "    ds.attrs[\"description\"] = \"Tiny NetCDF file for interpolation testing\"\n",
    "    ds.attrs[\"created_by\"] = \"Gemini LLM\"\n",
    "\n",
    "    # 5. Save the xarray Dataset to a .nc file\n",
    "    ds.to_netcdf(filename)\n",
    "    print(f\"Tiny NetCDF file '{filename}' created successfully in the current directory.\")\n",
    "    print(\"\\nDataset structure:\")\n",
    "    print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tiny_netcdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = xr.open_dataset(\"tiny_temp_data.nc\")\n",
    "ds = xr.open_dataset(era5_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.rio.write_crs(\"EPSG:4326\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set spatial dimensions (if not automatically recognized, though rioxarray is good at this)\n",
    "ds = ds.rio.set_spatial_dims(x_dim=\"longitude\", y_dim=\"latitude\", inplace=True)\n",
    "\n",
    "ds = ds.rename({\"valid_time\": \"band\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the first time slice of the temperature DataArray as a GeoTIFF\n",
    "output_filename = \"my_xarray_data.tif\"\n",
    "ds.t2m.rio.to_raster(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your .tif file\n",
    "file_path = output_filename  # Replace with the actual path to your .tif file\n",
    "\n",
    "# Open the .tif file as an xarray DataArray\n",
    "try:\n",
    "    raster_data = rioxarray.open_rasterio(file_path)\n",
    "    print(\"Successfully opened the .tif file:\")\n",
    "    print(raster_data)\n",
    "except Exception as e:\n",
    "    print(f\"Error opening the .tif file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    verify_raster = rioxarray.open_rasterio(output_filename)\n",
    "    print(\"\\nSuccessfully re-opened the saved multi-band raster for verification:\")\n",
    "    print(verify_raster)\n",
    "    # You can plot individual bands or all bands if matplotlib supports it\n",
    "    # import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Plot the first band (first time step)\n",
    "    verify_raster.isel(band=0).plot(\n",
    "        ax=plt.subplot(1, 2, 1),\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kwargs={\"label\": \"Processed Temperature (Band 0)\"},\n",
    "    )\n",
    "    plt.title(\"First Time Step/Band\")\n",
    "    # Plot the second band (second time step)\n",
    "    verify_raster.isel(band=1).plot(\n",
    "        ax=plt.subplot(1, 2, 2),\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kwargs={\"label\": \"Processed Temperature (Band 1)\"},\n",
    "    )\n",
    "    plt.title(\"Second Time Step/Band\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"\\nError verifying saved raster: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_onehealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
